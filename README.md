# Hedge Algebra Clustering

Module ph√¢n c·ª•m d·ª±a tr√™n ƒê·∫°i s·ªë gia t·ª≠ (Hedge Algebra) v·ªõi kh·∫£ nƒÉng:
- Load d·ªØ li·ªáu t·ª´ CSV ho·∫∑c NPY
- Ti·ªÅn x·ª≠ l√Ω t·ª± ƒë·ªông (normalize, feature selection)
- Ph√¢n c·ª•m b·∫±ng ƒê·∫°i s·ªë gia t·ª≠ (m·∫∑c ƒë·ªãnh 2‚Äì10 c·ª•m, **h·ªó tr·ª£ N l·ªõn h∆°n v·ªõi fallback & warning**)
- **üÜï Dual Init Mode (`center_init`)**: chuy·ªÉn ƒë·ªïi linh ho·∫°t gi·ªØa **Ver6** (m·ªõi) v√† **Legacy** (c≈©) ƒë·ªÉ A/B testing
- **üÜï Semantic Scaling**: co gi√£n t√¢m c·ª•m l√Ω thuy·∫øt `[0,1]` v√†o d·∫£i ng·ªØ nghƒ©a th·ª±c t·∫ø `[min(Sd), max(Sd)]` ƒë·ªÉ ·ªïn ƒë·ªãnh h∆°n tr√™n d·ªØ li·ªáu co c·ª•m
- **üÜï Auto cluster**: T·ª± ƒë·ªông ch·∫°y t·ª´ 2-9 c·ª•m v√† ch·ªçn c·∫•u h√¨nh t·ªët nh·∫•t
- **üÜï Batch processing**: X·ª≠ l√Ω dataset l·ªõn (h√†ng tri·ªáu d√≤ng) kh√¥ng tr√†n RAM
- **üÜï Memory management**: Gi·ªõi h·∫°n RAM s·ª≠ d·ª•ng
- **üÜï Numpy vectorization**: T·ªëi ∆∞u t·ªëc ƒë·ªô x·ª≠ l√Ω
- **üÜï Clustering metrics**: Partition Coefficient (PC), Classification Entropy (CE), Xie-Beni Index (XB)
- Training ML model cho t·ª´ng c·ª•m
- ƒê√°nh gi√° v√† logging chi ti·∫øt

---

## C√†i ƒë·∫∑t Dependencies

```bash
pip install numpy pandas scikit-learn joblib psutil
```

---

## C√°ch s·ª≠ d·ª•ng

### 1. S·ª≠ d·ª•ng c∆° b·∫£n (v·ªõi file CSV)

```python
from src import HedgeAlgebraPipeline

pipeline = HedgeAlgebraPipeline(
    n_clusters=3,
    theta=0.5,
    alpha=0.5
)

result = pipeline.run("data.csv", label_column="target")

print(f"Accuracy: {result.accuracy:.4f}")
print(result.summary())
```

### 2. S·ª≠ d·ª•ng v·ªõi d·ªØ li·ªáu c√≥ s·∫µn

```python
from src import HedgeAlgebraPipeline

pipeline = HedgeAlgebraPipeline(n_clusters=3)
result = pipeline.run_with_data(X_train, X_test, y_train, y_test)

print(f"Accuracy: {result.accuracy:.4f}")
```

### 3. S·ª≠ d·ª•ng quick_run (nhanh nh·∫•t)

```python
from src.pipeline import quick_run

result = quick_run("data.csv", n_clusters=3, label_column="target")
print(f"Accuracy: {result.accuracy:.4f}")
```

### 4. T·ªëi ∆∞u h√≥a tham s·ªë t·ª± ƒë·ªông (Optimizer Full-Fit)

> Optimizer ch·∫°y **full-fit** (l·∫∑p ƒë·∫øn h·ªôi t·ª•) cho m·ªói (Œ∏, Œ±) ‚Üí loss ƒë∆∞·ª£c t√≠nh tr√™n tr·∫°ng th√°i h·ªôi t·ª•.

```python
from src import HedgeAlgebraPipeline

pipeline = HedgeAlgebraPipeline(
    n_clusters=3,
    optimize_parameters=True
)
result = pipeline.run("data.csv")

print(f"Best theta: {result.theta:.4f}")
print(f"Best alpha: {result.alpha:.4f}")
```

### 5. S·ª≠ d·ª•ng Information Gain

```python
from src import HedgeAlgebraPipeline

pipeline = HedgeAlgebraPipeline(
    n_clusters=3,
    use_information_gain=True
)
result = pipeline.run("data.csv")
```

### 6. S·ª≠ d·ª•ng ML model kh√°c

```python
from sklearn.ensemble import RandomForestClassifier
from src import HedgeAlgebraPipeline

pipeline = HedgeAlgebraPipeline(
    n_clusters=3,
    classifier=RandomForestClassifier(n_estimators=100)
)
result = pipeline.run("data.csv")
```

---

## üÜï Dual Init Mode (`center_init`): Ver6 vs Legacy

T·ª´ Ver 6.5, module h·ªó tr·ª£ **2 ch·∫ø ƒë·ªô kh·ªüi t·∫°o t√¢m c·ª•m**:

- `center_init="ver6"` (m·∫∑c ƒë·ªãnh): kh·ªüi t·∫°o theo **h·∫°ng t·ª≠ ng·ªØ nghƒ©a** (C/LC/VC + Œ∏) v√† heuristic ƒë·∫£m b·∫£o th·ª© t·ª± ng·ªØ nghƒ©a.
- `center_init="legacy"`: kh·ªüi t·∫°o theo **logic code c≈©** (tuy·∫øn t√≠nh a/2, a/4‚Ä¶).

V√≠ d·ª• d√πng tr·ª±c ti·∫øp `HedgeAlgebraClustering`:

```python
from src.clustering import HedgeAlgebraClustering

# Mode m·ªõi (Ver6) - m·∫∑c ƒë·ªãnh
model_ver6 = HedgeAlgebraClustering(n_clusters=6, theta=0.5, alpha=0.5, center_init="ver6")
res1 = model_ver6.fit(X)

# Mode c≈© (Legacy)
model_legacy = HedgeAlgebraClustering(n_clusters=6, theta=0.5, alpha=0.5, center_init="legacy")
res2 = model_legacy.fit(X)
```

T·ªëi ∆∞u tham s·ªë theo ƒë√∫ng init mode:

```python
from src.clustering import ParameterOptimizer

opt = ParameterOptimizer(center_init="legacy")  # ho·∫∑c "ver6"
best_theta, best_alpha, loss = opt.optimize(X, n_clusters=6)
print(best_theta, best_alpha, loss)
```

> L∆∞u √Ω: N·∫øu b·∫°n d√πng Pipeline v√† mu·ªën ƒë·ªïi init mode, h√£y ki·ªÉm tra Pipeline c√≥ forward tham s·ªë `center_init` hay kh√¥ng. N·∫øu ch∆∞a, c√≥ th·ªÉ th√™m 1 tham s·ªë `center_init` v√†o Pipeline v√† truy·ªÅn xu·ªëng `HedgeAlgebraClustering`.

---

## üÜï Auto Cluster (2-9 c·ª•m t·ª± ƒë·ªông)

```python
from src import AutoClusterPipeline, auto_cluster

# C√°ch 1: H√†m ti·ªán √≠ch
result = auto_cluster(X, min_clusters=2, max_clusters=9)
print(f"Best: {result.best_n_clusters} clusters")
print(result.summary())

# C√°ch 2: Pipeline
auto_pipeline = AutoClusterPipeline(
    min_clusters=2,
    max_clusters=9,
    optimize_params=True
)
result = auto_pipeline.run(X, selection_metric="silhouette")
```

### üÜï Auto Cluster v·ªõi Pipeline (Train + Predict)

```python
from src import HedgeAlgebraPipeline

pipeline = HedgeAlgebraPipeline()
result, auto_result = pipeline.run_auto_cluster(
    X_train, X_test, y_train, y_test,
    min_clusters=2,
    max_clusters=9
)

print(f"Best clusters: {auto_result.best_n_clusters}")
print(f"Accuracy: {result.accuracy:.4f}")
```

---

## üÜï X·ª≠ l√Ω Dataset l·ªõn (Batch Processing)

```python
from src import BatchProcessor, LargeDatasetPipeline

# C√°ch 1: BatchProcessor
processor = BatchProcessor(max_memory_gb=4.0)
for batch_X, batch_y, info in processor.iterate_batches(X, y, batch_size=10000):
    process(batch_X)

# C√°ch 2: LargeDatasetPipeline
pipeline = LargeDatasetPipeline(max_memory_gb=8.0)
result = pipeline.run("large_data.csv", n_clusters=5, sample_for_training=100000)
```

### üÜï Quick Auto Run

```python
from src.pipeline import quick_auto_run

result, auto_result = quick_auto_run(
    "data.csv",
    min_clusters=2,
    max_clusters=9,
    label_column="target"
)
```

---

## üÜï Clustering Evaluation Metrics

```python
from src import ClusteringEvaluator, quick_evaluate
from src.clustering import HedgeAlgebraClustering

# C√°ch 1: Evaluator
evaluator = ClusteringEvaluator()
metrics = evaluator.evaluate(X, cluster_labels, cluster_centers)
print(metrics.summary())

# C√°ch 2: Quick evaluate
metrics = quick_evaluate(X, cluster_labels, cluster_centers)

# Metrics t·ª± ƒë·ªông trong clustering result
clustering = HedgeAlgebraClustering(n_clusters=3)
result = clustering.fit(X)
if result.metrics:
    print(result.metrics.summary())
```

---

## C·∫•u tr√∫c Module

```
codebase_project/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ logger.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ clustering.py
‚îÇ   ‚îú‚îÄ‚îÄ classifier.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ auto_cluster.py
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.py
‚îÇ   ‚îî‚îÄ‚îÄ clustering_metrics.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_clustering.py
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ test_auto_cluster.py
‚îÇ   ‚îî‚îÄ‚îÄ test_clustering_metrics.py
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ example_usage.py
‚îî‚îÄ‚îÄ logs/
```

---

## PipelineResult

| Attribute | M√¥ t·∫£ |
|-----------|-------|
| `accuracy` | ƒê·ªô ch√≠nh x√°c |
| `precision` | Precision (macro) |
| `recall` | Recall (macro) |
| `f1` | F1-score (macro) |
| `training_time` | Th·ªùi gian training (s) |
| `testing_time` | Th·ªùi gian testing (s) |
| `n_clusters` | S·ªë c·ª•m |
| `cluster_centers` | T√¢m c√°c c·ª•m |
| `cluster_distribution` | Ph√¢n b·ªë samples trong c·ª•m |
| `classification_report` | B√°o c√°o ph√¢n lo·∫°i chi ti·∫øt |
| `theta` | Tham s·ªë theta |
| `alpha` | Tham s·ªë alpha |

---

## Ch·∫°y Tests

```bash
cd codebase_project

python tests/test_clustering.py
python tests/test_pipeline.py
python tests/test_auto_cluster.py
python tests/test_clustering_metrics.py

python examples/example_usage.py
```

---

## üÜï AutoClusterResult

| Attribute | M√¥ t·∫£ |
|-----------|-------|
| `best_n_clusters` | S·ªë c·ª•m t·ªët nh·∫•t |
| `best_evaluation` | ƒê√°nh gi√° c·ªßa c·∫•u h√¨nh t·ªët nh·∫•t |
| `all_evaluations` | Danh s√°ch ƒë√°nh gi√° t·∫•t c·∫£ c·∫•u h√¨nh |
| `total_time` | T·ªïng th·ªùi gian ch·∫°y |

---

## üÜï Memory Configuration

```python
from src import BatchProcessor, MemoryConfig

config = MemoryConfig(
    max_memory_gb=4.0,
    batch_size=10000,
    reserve_memory_gb=1.0
)

processor = BatchProcessor(max_memory_gb=4.0)
```

---

## üÜï Clustering Evaluation Metrics

Module cung c·∫•p 3 ch·ªâ s·ªë ƒë√°nh gi√° ph√¢n c·ª•m ch√≠nh:

### 1. Partition Coefficient (PC)
- **√ù nghƒ©a**: m·ª©c ƒë·ªô ph√¢n bi·ªát v√† ƒë·ªô t·∫≠p trung c·ªßa c√°c c·ª•m m·ªù
- **Range**: [1/n_clusters, 1]
- **C√†ng cao c√†ng t·ªët**

### 2. Classification Entropy (CE)
- **√ù nghƒ©a**: m·ª©c ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn trong ph√¢n c·ª•m
- **Range**: [0, 1] (normalized)
- **C√†ng th·∫•p c√†ng t·ªët**

### 3. Xie-Beni Index (XB)
- **√ù nghƒ©a**: t·ª∑ l·ªá compactness/separation
- **Range**: > 0
- **C√†ng th·∫•p c√†ng t·ªët**

V√≠ d·ª• output:

```
============================================================
üìä CLUSTERING EVALUATION METRICS
============================================================

Partition Coefficient (PC):     0.823456 (‚Üë cao h∆°n = t·ªët h∆°n)
Classification Entropy (CE):     0.234567 (‚Üì th·∫•p h∆°n = t·ªët h∆°n)
Xie-Beni Index (XB):             0.012345 (‚Üì th·∫•p h∆°n = t·ªët h∆°n)
Silhouette Score:                0.789012 (‚Üë cao h∆°n = t·ªët h∆°n)

============================================================
```

---

## L√Ω thuy·∫øt ƒê·∫°i s·ªë gia t·ª≠ (t√≥m t·∫Øt)

ƒê·∫°i s·ªë gia t·ª≠ (Hedge Algebra) l√† framework to√°n h·ªçc ƒë·ªÉ bi·ªÉu di·ªÖn c√°c kh√°i ni·ªám m·ªù nh∆∞ "r·∫•t cao", "kh√° th·∫•p", "trung b√¨nh".

### Lu·ªìng ph√¢n c·ª•m (t√≥m t·∫Øt)
1) Chu·∫©n h√≥a d·ªØ li·ªáu ‚Üí t√≠nh gi√° tr·ªã ng·ªØ nghƒ©a `Sd_i` (mean theo sample)
2) Kh·ªüi t·∫°o t√¢m c·ª•m `SC_k` (Ver6 ho·∫∑c Legacy)
3) G√°n c·ª•m theo midpoint: n·∫øu `x <= midpoint` ‚Üí c·ª•m tr√°i
4) C·∫≠p nh·∫≠t t√¢m = trung b√¨nh `Sd_i` trong c·ª•m (c·ª•m r·ªóng gi·ªØ t√¢m c≈©)
5) L·∫∑p ƒë·∫øn h·ªôi t·ª•

### Semantic Scaling
T√¢m c·ª•m l√Ω thuy·∫øt `[0,1]` ƒë∆∞·ª£c map v√†o d·∫£i th·ª±c t·∫ø `[min(Sd), max(Sd)]` ƒë·ªÉ gi·∫£m r·ªßi ro c·ª•m r·ªóng khi d·ªØ li·ªáu co c·ª•m.

---

## T√°c gi·∫£

Nguyen Van Nhan
ICN-Lab

## License

MIT

