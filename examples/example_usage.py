"""
V√≠ d·ª• s·ª≠ d·ª•ng Hedge Algebra Clustering Pipeline

File n√†y minh h·ªça c√°c c√°ch s·ª≠ d·ª•ng module:
1. S·ª≠ d·ª•ng c∆° b·∫£n v·ªõi file CSV
2. S·ª≠ d·ª•ng v·ªõi d·ªØ li·ªáu c√≥ s·∫µn
3. S·ª≠ d·ª•ng v·ªõi t·ªëi ∆∞u h√≥a tham s·ªë
4. S·ª≠ d·ª•ng v·ªõi Information Gain
5. S·ª≠ d·ª•ng v·ªõi c√°c ML models kh√°c nhau
"""

import numpy as np
import pandas as pd
import sys
from pathlib import Path

# Th√™m path ƒë·ªÉ import module
sys.path.insert(0, str(Path(__file__).parent.parent))

from src import HedgeAlgebraPipeline
from src.pipeline import quick_run


def create_sample_data():
    """T·∫°o d·ªØ li·ªáu m·∫´u ƒë·ªÉ demo."""
    np.random.seed(42)
    
    n_samples = 200
    n_features = 10
    n_classes = 3
    
    # T·∫°o d·ªØ li·ªáu ph√¢n bi·ªát theo class
    X_list = []
    y_list = []
    
    samples_per_class = n_samples // n_classes
    for class_id in range(n_classes):
        base = class_id * 0.3
        X_class = np.random.uniform(base, base + 0.25, (samples_per_class, n_features))
        X_list.append(X_class)
        y_list.extend([class_id] * samples_per_class)
    
    X = np.vstack(X_list)
    y = np.array(y_list)
    
    # Shuffle
    indices = np.random.permutation(len(y))
    X = X[indices]
    y = y[indices]
    
    return X, y


def example_1_basic_usage():
    """
    V√≠ d·ª• 1: S·ª≠ d·ª•ng c∆° b·∫£n
    
    ƒê√¢y l√† c√°ch ƒë∆°n gi·∫£n nh·∫•t ƒë·ªÉ s·ª≠ d·ª•ng pipeline.
    """
    print("\n" + "=" * 70)
    print("üìå V√ç D·ª§ 1: S·ª¨ D·ª§NG C∆† B·∫¢N")
    print("=" * 70)
    
    # T·∫°o d·ªØ li·ªáu
    X, y = create_sample_data()
    
    # Chia train/test
    split_idx = int(0.8 * len(y))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    print(f"\nüìä D·ªØ li·ªáu:")
    print(f"   Train: {X_train.shape[0]} samples, {X_train.shape[1]} features")
    print(f"   Test: {X_test.shape[0]} samples")
    print(f"   Classes: {np.unique(y)}")
    
    # Kh·ªüi t·∫°o v√† ch·∫°y pipeline
    pipeline = HedgeAlgebraPipeline(
        n_clusters=3,           # S·ªë c·ª•m
        theta=0.5,              # Tham s·ªë theta
        alpha=0.5,              # Tham s·ªë alpha
        log_level="INFO",       # M·ª©c ƒë·ªô logging
        log_to_file=False       # Kh√¥ng ghi log ra file
    )
    
    # Ch·∫°y v·ªõi d·ªØ li·ªáu c√≥ s·∫µn
    result = pipeline.run_with_data(X_train, X_test, y_train, y_test)
    
    # In k·∫øt qu·∫£
    print(result.summary())


def example_2_with_csv():
    """
    V√≠ d·ª• 2: S·ª≠ d·ª•ng v·ªõi file CSV
    
    Pipeline t·ª± ƒë·ªông load, ti·ªÅn x·ª≠ l√Ω v√† train.
    """
    print("\n" + "=" * 70)
    print("üìå V√ç D·ª§ 2: S·ª¨ D·ª§NG V·ªöI FILE CSV")
    print("=" * 70)
    
    # T·∫°o file CSV m·∫´u
    X, y = create_sample_data()
    columns = [f'feature_{i}' for i in range(X.shape[1])] + ['target']
    data = np.column_stack([X, y])
    df = pd.DataFrame(data, columns=columns)
    
    csv_path = "/tmp/sample_data.csv"
    df.to_csv(csv_path, index=False)
    print(f"\nüìÅ ƒê√£ t·∫°o file CSV: {csv_path}")
    print(f"   Shape: {df.shape}")
    
    # Ch·∫°y pipeline v·ªõi file CSV
    pipeline = HedgeAlgebraPipeline(
        n_clusters=3,
        log_level="INFO",
        log_to_file=False
    )
    
    result = pipeline.run(
        file_path=csv_path,
        label_column='target',      # T√™n c·ªôt label
        normalize_method='minmax'   # Ph∆∞∆°ng ph√°p chu·∫©n h√≥a
    )
    
    print(result.summary())
    
    # Cleanup
    Path(csv_path).unlink()


def example_3_with_optimization():
    """
    V√≠ d·ª• 3: S·ª≠ d·ª•ng v·ªõi t·ªëi ∆∞u h√≥a tham s·ªë
    
    Pipeline t·ª± ƒë·ªông t√¨m theta v√† alpha t·ªëi ∆∞u.
    """
    print("\n" + "=" * 70)
    print("üìå V√ç D·ª§ 3: T·ªêI ∆ØU H√ìA THAM S·ªê")
    print("=" * 70)
    
    X, y = create_sample_data()
    split_idx = int(0.8 * len(y))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    pipeline = HedgeAlgebraPipeline(
        n_clusters=3,
        optimize_parameters=True,   # B·∫≠t t·ªëi ∆∞u h√≥a
        log_level="INFO",
        log_to_file=False
    )
    
    result = pipeline.run_with_data(X_train, X_test, y_train, y_test)
    
    print(f"\nüìä Tham s·ªë ƒë∆∞·ª£c t·ªëi ∆∞u:")
    print(f"   Theta: {result.theta:.4f}")
    print(f"   Alpha: {result.alpha:.4f}")
    print(result.summary())


def example_4_with_information_gain():
    """
    V√≠ d·ª• 4: S·ª≠ d·ª•ng v·ªõi Information Gain
    
    S·ª≠ d·ª•ng IG Ratio l√†m tr·ªçng s·ªë cho features.
    """
    print("\n" + "=" * 70)
    print("üìå V√ç D·ª§ 4: S·ª¨ D·ª§NG INFORMATION GAIN")
    print("=" * 70)
    
    X, y = create_sample_data()
    split_idx = int(0.8 * len(y))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # T√≠nh IG ratio t·ª´ DataLoader
    from src.data_loader import DataLoader
    
    loader = DataLoader(log_level="INFO")
    ig_weights = loader.calculate_information_gain_ratio(X_train, y_train)
    print(f"\nüìä Information Gain Ratio: {ig_weights}")
    
    pipeline = HedgeAlgebraPipeline(
        n_clusters=3,
        use_information_gain=True,
        log_level="INFO",
        log_to_file=False
    )
    
    result = pipeline.run_with_data(
        X_train, X_test, y_train, y_test,
        information_gain_weights=ig_weights
    )
    
    print(result.summary())


def example_5_different_classifiers():
    """
    V√≠ d·ª• 5: S·ª≠ d·ª•ng v·ªõi c√°c ML models kh√°c nhau
    
    C√≥ th·ªÉ d√πng b·∫•t k·ª≥ sklearn classifier n√†o.
    """
    print("\n" + "=" * 70)
    print("üìå V√ç D·ª§ 5: C√ÅC ML MODELS KH√ÅC NHAU")
    print("=" * 70)
    
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.svm import SVC
    
    X, y = create_sample_data()
    split_idx = int(0.8 * len(y))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    classifiers = {
        'Decision Tree': DecisionTreeClassifier(random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42),
        'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, random_state=42),
    }
    
    results = {}
    
    for name, clf in classifiers.items():
        print(f"\nüîß Testing: {name}")
        
        pipeline = HedgeAlgebraPipeline(
            n_clusters=3,
            classifier=clf,
            log_level="WARNING",
            log_to_file=False
        )
        
        result = pipeline.run_with_data(X_train, X_test, y_train, y_test)
        results[name] = result.accuracy
        
        print(f"   Accuracy: {result.accuracy:.4f}")
    
    # So s√°nh k·∫øt qu·∫£
    print("\n" + "=" * 50)
    print("üìä SO S√ÅNH K·∫æT QU·∫¢")
    print("=" * 50)
    
    for name, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):
        print(f"   {name}: {acc:.4f}")


def example_6_quick_run():
    """
    V√≠ d·ª• 6: S·ª≠ d·ª•ng quick_run
    
    C√°ch nhanh nh·∫•t ƒë·ªÉ ch·∫°y pipeline.
    """
    print("\n" + "=" * 70)
    print("üìå V√ç D·ª§ 6: QUICK RUN")
    print("=" * 70)
    
    # T·∫°o file CSV
    X, y = create_sample_data()
    columns = [f'f{i}' for i in range(X.shape[1])] + ['label']
    data = np.column_stack([X, y])
    df = pd.DataFrame(data, columns=columns)
    
    csv_path = "/tmp/quick_data.csv"
    df.to_csv(csv_path, index=False)
    
    # Quick run
    result = quick_run(csv_path, n_clusters=3, label_column='label')
    
    print(result.summary())
    
    # Cleanup
    Path(csv_path).unlink()


def example_7_different_cluster_counts():
    """
    V√≠ d·ª• 7: So s√°nh s·ªë c·ª•m kh√°c nhau
    """
    print("\n" + "=" * 70)
    print("üìå V√ç D·ª§ 7: SO S√ÅNH S·ªê C·ª§M KH√ÅC NHAU")
    print("=" * 70)
    
    X, y = create_sample_data()
    split_idx = int(0.8 * len(y))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    results = {}
    
    for n_clusters in [2, 3, 4, 5]:
        pipeline = HedgeAlgebraPipeline(
            n_clusters=n_clusters,
            log_level="ERROR",
            log_to_file=False
        )
        
        result = pipeline.run_with_data(X_train, X_test, y_train, y_test)
        results[n_clusters] = {
            'accuracy': result.accuracy,
            'f1': result.f1,
            'centers': result.cluster_centers
        }
    
    print("\nüìä SO S√ÅNH ACCURACY V·ªöI S·ªê C·ª§M KH√ÅC NHAU")
    print("-" * 50)
    
    for n, r in results.items():
        centers_str = ", ".join([f"{c:.3f}" for c in r['centers']])
        print(f"   {n} c·ª•m: Acc={r['accuracy']:.4f}, F1={r['f1']:.4f}")
        print(f"          Centers: [{centers_str}]")


if __name__ == "__main__":
    print("\n" + "üöÄ" * 35)
    print("      HEDGE ALGEBRA CLUSTERING - V√ç D·ª§ S·ª¨ D·ª§NG")
    print("üöÄ" * 35)
    
    # Ch·∫°y c√°c v√≠ d·ª•
    example_1_basic_usage()
    example_2_with_csv()
    example_3_with_optimization()
    example_4_with_information_gain()
    example_5_different_classifiers()
    example_6_quick_run()
    example_7_different_cluster_counts()
    
    print("\n" + "=" * 70)
    print("‚úÖ HO√ÄN T·∫§T T·∫§T C·∫¢ C√ÅC V√ç D·ª§")
    print("=" * 70)

